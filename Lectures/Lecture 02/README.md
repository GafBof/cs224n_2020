# Lecture 2: Word Vectors, WordSenses and Classifier Review

## Table of content
1. [Word2vec](#word2vec)
1. [Gradient Descent](#gradient-descent)
1. [Co-occurrence matrix](#co-occurrence-matrix)
1. [GloVe](#glove)
1. [Evaluate word vectors](#evaluate-word-vectors)
1. [Word senses and word sense ambiguity](#word-senses-and-word-sense-ambiguity)
1. [Classification review and notation](#classification-review-and-notation)
1. [Reference](#reference)

## Word2vec

## Gradient Descent

## Co-occurrence matrix

## GloVe

## Evaluate word vectors

## Word senses and word sense ambiguity

## Classification review and notation

## Reference

- [Slide](http://web.stanford.edu/class/cs224n/slides/cs224n-2020-lecture02-wordvecs2.pdf)
- [Note](http://web.stanford.edu/class/cs224n/readings/cs224n-2019-notes02-wordvecs2.pdf)
- Suggested Readings:
    1. [GloVe: Global Vectors for Word Representation](http://nlp.stanford.edu/pubs/glove.pdf)
    2. [Improving Distributional Similarity with Lessons Learned from Word Embeddings](http://www.aclweb.org/anthology/Q15-1016)
    3. [Evaluation methods for unsupervised word embeddings](http://www.aclweb.org/anthology/D15-1036)
    4. [A Latent Variable Model Approach to PMI-based Word Embeddings](http://aclweb.org/anthology/Q16-1028)
    5. [Linear Algebraic Structure of Word Senses, with Applications to Polysemy](https://transacl.org/ojs/index.php/tacl/article/viewFile/1346/320)
    6. [On the Dimensionality of Word Embedding](https://papers.nips.cc/paper/7368-on-the-dimensionality-of-word-embedding.pdf)
